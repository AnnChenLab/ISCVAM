{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['artifacts', 'assaysData']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "#filename = '/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/data/demo/test_discover_42.h5'\n",
    "filename = '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_thanh_update/orchestration/docker_files/compose/datasets/SKCM_GSE72056.h5'\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    print(f.keys())  # List all top-level groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['artifacts', 'assaysData']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "filename = '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/SKCM_GSE115978_aPD1.pipeline.4.h5'\n",
    "\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    print(f.keys())  # List all top-level groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate dataset names: []\n"
     ]
    }
   ],
   "source": [
    "#find duplication in app-setting (frontend)\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your JSON file\n",
    "json_file_path = \"/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/frontend/public/app-settings.json\"\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract the dataset names\n",
    "dataset_names = [dataset['name'] for dataset in json_data['datasets']]\n",
    "\n",
    "# Find duplicate names using a Counter\n",
    "name_counts = Counter(dataset_names)\n",
    "duplicates = [name for name, count in name_counts.items() if count > 1]\n",
    "\n",
    "# Output the duplicate names\n",
    "print(\"Duplicate dataset names:\", duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate dataset names: []\n"
     ]
    }
   ],
   "source": [
    "#find duplication in dataset (backend)\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your JSON file\n",
    "json_file_path = \"/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/backend/datasets.json\"\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract dataset names and find duplicates\n",
    "dataset_names = [dataset['name'] for dataset in json_data]\n",
    "name_counts = Counter(dataset_names)\n",
    "duplicates = [name for name, count in name_counts.items() if count > 1]\n",
    "\n",
    "# Output the duplicate names\n",
    "print(\"Duplicate dataset names:\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleted dataset (frontend)\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "#Path to json\n",
    "new_json = \"/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/frontend/public/app-settings.json\"\n",
    "old_json = \"/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/frontend/public/backup-app-settings.json\"\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(new_json, 'r') as file:\n",
    "    new_json_data = json.load(file)\n",
    "\n",
    "with open(old_json, 'r') as file:\n",
    "    old_json_data = json.load(file)\n",
    "\n",
    "new_dataset_names = [dataset['name'] for dataset in new_json_data['datasets']]\n",
    "old_dataset_names = [dataset['name'] for dataset in old_json_data['datasets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GSE189341-acral-sc-seuratV4', 'SKCM_GSE123139', 'KIRC_GSE159115', 'SKCM_GSE179373', 'SKCM_GSE115978_aPD1 - Endo avail', 'UVM_GSE138433 - Endo avail', 'UVM_GSE139829', 'multiome_int.validation test', 'multiome_discovery WNN', 'BRCA GSE148673', 'multiome_discovery', 'multiome_validation', 'SKCM_GSE148190', 'multiome_int.validation', 'multiome_PBMC_test', 'SKCM_GSE166181_aPD1', 'UVM_GSE160883', 'multiome_discovery test', 'SKCM_GSE159251', 'SKCM_GSE120575_aPD1aCTLA4', 'SKCM_GSE134388_aPD1 - Endo avail', 'UVM_GSE169609', 'SKCM_GSE139249']\n"
     ]
    }
   ],
   "source": [
    "# Convert the lists to sets\n",
    "set1 = set(new_dataset_names)\n",
    "set2 = set(old_dataset_names)\n",
    "\n",
    "# Find the symmetric difference (elements that are in either set1 or set2, but not in both)\n",
    "different_elements = set1.symmetric_difference(set2)\n",
    "\n",
    "# Convert the result back to a list (if needed)\n",
    "different_elements_list = list(different_elements)\n",
    "\n",
    "# Print the result\n",
    "print(different_elements_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GSE189341-acral-sc-seuratV4',\n",
       " 'SKCM_GSE123139',\n",
       " 'KIRC_GSE159115',\n",
       " 'SKCM_GSE179373',\n",
       " 'SKCM_GSE115978_aPD1 - Endo avail',\n",
       " 'UVM_GSE138433 - Endo avail',\n",
       " 'UVM_GSE139829',\n",
       " 'multiome_int.validation test',\n",
       " 'multiome_discovery WNN',\n",
       " 'BRCA GSE148673',\n",
       " 'multiome_discovery',\n",
       " 'multiome_validation',\n",
       " 'SKCM_GSE148190',\n",
       " 'multiome_int.validation',\n",
       " 'multiome_PBMC_test',\n",
       " 'SKCM_GSE166181_aPD1',\n",
       " 'UVM_GSE160883',\n",
       " 'multiome_discovery test',\n",
       " 'SKCM_GSE159251',\n",
       " 'SKCM_GSE120575_aPD1aCTLA4',\n",
       " 'SKCM_GSE134388_aPD1 - Endo avail',\n",
       " 'UVM_GSE169609',\n",
       " 'SKCM_GSE139249']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "different_elements_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated JSON file, duplicates removed.\n"
     ]
    }
   ],
   "source": [
    "#remove duplicate\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your JSON file\n",
    "json_file_path = \"/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/frontend/public/app-settings.json\"\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract dataset names and find duplicates\n",
    "dataset_names = [dataset['name'] for dataset in json_data['datasets']]\n",
    "name_counts = Counter(dataset_names)\n",
    "\n",
    "# Set to keep track of names that have already been seen\n",
    "seen_names = set()\n",
    "\n",
    "# List to hold unique datasets\n",
    "unique_datasets = []\n",
    "\n",
    "for dataset in json_data['datasets']:\n",
    "    name = dataset['name']\n",
    "    \n",
    "    # If the name has not been seen yet, add it to the unique datasets\n",
    "    if name not in seen_names:\n",
    "        unique_datasets.append(dataset)\n",
    "        seen_names.add(name)\n",
    "    # If it's the first duplicate, skip it\n",
    "    elif name_counts[name] > 1:\n",
    "        name_counts[name] -= 1  # Decrease count for that name\n",
    "\n",
    "# Update the JSON data with the unique datasets\n",
    "json_data['datasets'] = unique_datasets\n",
    "\n",
    "# Write the updated JSON data back to the file\n",
    "with open(json_file_path, 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)\n",
    "\n",
    "print(\"Updated JSON file, duplicates removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names with 'docker_files' in filename: ['GSE189341-acral-sc-old', 'GSE189341-acral-sc', 'UVM_GSE169609', 'UVM_GSE160883', 'UVM_GSE138433', 'SKCM_GSE179373', 'SKCM_GSE166181_aPD1', 'SKCM_GSE159251', 'SKCM_GSE148190', 'SKCM_GSE139249', 'SKCM_GSE134388_aPD1', 'SKCM_GSE123139', 'SKCM_GSE120575_aPD1aCTLA4', 'SKCM_GSE72056', 'SKCM_GSE115978_aPD1', 'UVM_GSE139829_update.curated', 'UVM_GSE139829_2stages', 'UVM_GSE139829', 'KIRC_GSE159115', 'BRCA GSE148673', 'Acral melanoma', 'Smalley project']\n"
     ]
    }
   ],
   "source": [
    "#find duplication in dataset docker folder(backend)\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your JSON file\n",
    "json_file_path = \"/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/backend/datasets.json\"\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Filter the data to find entries where 'filename' contains 'docker_files'\n",
    "data_in_docker = [entry['name'] for entry in json_data if 'docker_files' in entry['filename']]\n",
    "\n",
    "# Print the filtered names\n",
    "print(\"Names with 'docker_files' in filename:\", data_in_docker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of filtered names with their related names:\n",
      "GSE189341-acral-sc-old: []\n",
      "GSE189341-acral-sc: []\n",
      "UVM_GSE169609: [{'name': 'UVM_GSE169609.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/iscvam_complied_h5/UVM_GSE169609.pipeline.h5'}]\n",
      "UVM_GSE160883: [{'name': 'UVM_GSE160883.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/iscvam_complied_h5/UVM_GSE160883.pipeline.h5'}]\n",
      "UVM_GSE138433: [{'name': 'UVM_GSE138433.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/iscvam_complied_h5/UVM_GSE138433.pipeline.h5'}]\n",
      "SKCM_GSE179373: [{'name': 'SKCM_GSE179373.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/iscvam_complied_h5/SKCM_GSE179373.pipeline.h5'}]\n",
      "SKCM_GSE166181_aPD1: [{'name': 'SKCM_GSE166181_aPD1.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/iscvam_complied_h5/SKCM_GSE166181_aPD1.pipeline.h5'}]\n",
      "SKCM_GSE159251: [{'name': 'SKCM_GSE159251.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/SKCM_GSE159251.pipeline.h5'}]\n",
      "SKCM_GSE148190: [{'name': 'SKCM_GSE148190.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/SKCM_GSE148190.pipeline.h5'}]\n",
      "SKCM_GSE139249: [{'name': 'SKCM_GSE139249.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/iscvam_complied_h5/SKCM_GSE139249.pipeline.h5'}]\n",
      "SKCM_GSE134388_aPD1: [{'name': 'SKCM_GSE134388_aPD1.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/iscvam_complied_h5/SKCM_GSE134388_aPD1.pipeline.h5'}]\n",
      "SKCM_GSE123139: [{'name': 'SKCM_GSE123139.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/SKCM_GSE123139.pipeline.h5'}]\n",
      "SKCM_GSE120575_aPD1aCTLA4: [{'name': 'SKCM_GSE120575_aPD1aCTLA4.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/iscvam_complied_h5/SKCM_GSE120575_aPD1aCTLA4.pipeline.h5'}]\n",
      "SKCM_GSE72056: []\n",
      "SKCM_GSE115978_aPD1: [{'name': 'SKCM_GSE115978_aPD1.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/SKCM_GSE115978_aPD1.pipeline.4.h5'}]\n",
      "UVM_GSE139829_update.curated: []\n",
      "UVM_GSE139829_2stages: []\n",
      "UVM_GSE139829: [{'name': 'UVM_GSE139829.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/UVM_GSE139829.pipeline.h5'}]\n",
      "KIRC_GSE159115: [{'name': 'KIRC_GSE159115.pipeline', 'filename': '/uufs/chpc.utah.edu/common/home/ychen-group1/ISCVAM_complied_h5/KIRC_GSE159115.pipeline.h5'}]\n",
      "BRCA GSE148673: []\n",
      "Acral melanoma: []\n",
      "Smalley project: []\n"
     ]
    }
   ],
   "source": [
    "# Filter to find entries related by name inclusion/exclusion excluding those in filtered_names\n",
    "data = json_data\n",
    "filtered_names = data_in_docker\n",
    "related_names_dict = {fn: [] for fn in filtered_names}\n",
    "related_entries = [\n",
    "    entry for entry in data \n",
    "    if any(fn in entry[\"name\"] or entry[\"name\"] in fn for fn in filtered_names) and entry[\"name\"] not in filtered_names\n",
    "]\n",
    "\n",
    "for fn in filtered_names:\n",
    "    for entry in data:\n",
    "        if (fn in entry[\"name\"] or entry[\"name\"] in fn) and entry[\"name\"] not in filtered_names:\n",
    "            related_names_dict[fn].append({\"name\": entry[\"name\"], \"filename\": entry[\"filename\"]})\n",
    " \n",
    " # Print the dictionary\n",
    "print(\"Dictionary of filtered names with their related names:\")\n",
    "for key, values in related_names_dict.items():\n",
    "    print(f\"{key}: {values}\")\n",
    "# Print the entries that include or are included by names in filtered_names, excluding the filtered_names themselves\n",
    "# print(\"Entries related by name inclusion/exclusion relationships excluding filtered_names:\")\n",
    "# for item in related_entries:\n",
    "#     print(f\"Name: {item['name']}, Filename: {item['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GSE189341-acral-sc-old',\n",
       " 'GSE189341-acral-sc',\n",
       " 'UVM_GSE169609',\n",
       " 'UVM_GSE160883',\n",
       " 'UVM_GSE138433',\n",
       " 'SKCM_GSE179373',\n",
       " 'SKCM_GSE166181_aPD1',\n",
       " 'SKCM_GSE159251',\n",
       " 'SKCM_GSE148190',\n",
       " 'SKCM_GSE139249',\n",
       " 'SKCM_GSE134388_aPD1',\n",
       " 'SKCM_GSE123139',\n",
       " 'SKCM_GSE120575_aPD1aCTLA4',\n",
       " 'SKCM_GSE72056',\n",
       " 'SKCM_GSE115978_aPD1',\n",
       " 'UVM_GSE139829_update.curated',\n",
       " 'UVM_GSE139829_2stages',\n",
       " 'UVM_GSE139829',\n",
       " 'KIRC_GSE159115',\n",
       " 'BRCA GSE148673',\n",
       " 'Acral melanoma',\n",
       " 'Smalley project']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in_docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Filtered Name                        Related Name  \\\n",
      "0               UVM_GSE169609              UVM_GSE169609.pipeline   \n",
      "1               UVM_GSE160883              UVM_GSE160883.pipeline   \n",
      "2               UVM_GSE138433              UVM_GSE138433.pipeline   \n",
      "3              SKCM_GSE179373             SKCM_GSE179373.pipeline   \n",
      "4         SKCM_GSE166181_aPD1        SKCM_GSE166181_aPD1.pipeline   \n",
      "5              SKCM_GSE159251             SKCM_GSE159251.pipeline   \n",
      "6              SKCM_GSE148190             SKCM_GSE148190.pipeline   \n",
      "7              SKCM_GSE139249             SKCM_GSE139249.pipeline   \n",
      "8         SKCM_GSE134388_aPD1        SKCM_GSE134388_aPD1.pipeline   \n",
      "9              SKCM_GSE123139             SKCM_GSE123139.pipeline   \n",
      "10  SKCM_GSE120575_aPD1aCTLA4  SKCM_GSE120575_aPD1aCTLA4.pipeline   \n",
      "11        SKCM_GSE115978_aPD1        SKCM_GSE115978_aPD1.pipeline   \n",
      "12              UVM_GSE139829              UVM_GSE139829.pipeline   \n",
      "13             KIRC_GSE159115             KIRC_GSE159115.pipeline   \n",
      "\n",
      "                                             Filename  \n",
      "0   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "1   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "2   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "3   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "4   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "5   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "6   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "7   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "8   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "9   /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "10  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "11  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "12  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "13  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n"
     ]
    }
   ],
   "source": [
    "# List to store rows for DataFrame\n",
    "table_data = []\n",
    "\n",
    "# Populate the list with related names and filenames excluding 'docker' in filenames\n",
    "for fn in filtered_names:\n",
    "    for entry in data:\n",
    "        if (fn in entry[\"name\"] or entry[\"name\"] in fn) and entry[\"name\"] not in filtered_names and \"docker\" not in entry[\"filename\"]:\n",
    "            table_data.append({\"Filtered Name\": fn, \"Related Name\": entry[\"name\"], \"Filename\": entry[\"filename\"]})\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(table_data)\n",
    "\n",
    "# Display DataFrame\n",
    "print(df)\n",
    "df.to_csv(\"similardataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take name and filename into a df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSON file\n",
    "import json\n",
    "import pandas as pd\n",
    "json_file_path = \"/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/backend/datasets.json\"\n",
    "metadata = pd.read_csv(\"/uufs/chpc.utah.edu/common/home/u6057318/Documents/ISCVAM_thanh_update/data_processing/merge.master_aug16_update.csv\")\n",
    "# Load the JSON data from the file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create DataFrame directly from JSON data\n",
    "df = pd.DataFrame(json_data)\n",
    "\n",
    "# Optionally, drop columns if you want only name and filename\n",
    "df = df[['name', 'filename']]  # This line is optional if your data only contains 'name' and 'filename'\n",
    "\n",
    "df['path'] = df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filename'] = df['path'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    test_discover_42.h5\n",
       "1                     PBMC_multiome_2.h5\n",
       "2      internal_validation_multiome_5.h5\n",
       "3                           GSE189341.h5\n",
       "4                 GSE189341.add.cts.1.h5\n",
       "                     ...                \n",
       "210            SCC_GSE145328.pipeline.h5\n",
       "211           SKCM_GSE148190.pipeline.h5\n",
       "212          NSCLC_GSE143423.pipeline.h5\n",
       "213           THCA_GSE148673.pipeline.h5\n",
       "214           SKCM_GSE123139.pipeline.h5\n",
       "Name: filename, Length: 215, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       AEL_GSE142213.pipeline.h5\n",
       "1       ALL_GSE132509.pipeline.h5\n",
       "2       ALL_GSE153697.pipeline.h5\n",
       "3       ALL_GSE154109.pipeline.h5\n",
       "4       AML_GSE116256.pipeline.h5\n",
       "                  ...            \n",
       "187    UCEC_GSE154763.pipeline.h5\n",
       "188     UVM_GSE138433.pipeline.h5\n",
       "189     UVM_GSE139829.pipeline.h5\n",
       "190     UVM_GSE160883.pipeline.h5\n",
       "191     UVM_GSE169609.pipeline.h5\n",
       "Name: file.name, Length: 192, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['file.name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dataset.Name    X  dataset.index       ID Species      Treatment  \\\n",
      "0  AEL_GSE142213   25             25  T010001   Human            NaN   \n",
      "1  ALL_GSE132509  148            148  T010002   Human            NaN   \n",
      "2  ALL_GSE153697   13             13  T020082   Human  Immunotherapy   \n",
      "3  ALL_GSE154109   81             81  T020083   Human            NaN   \n",
      "4  AML_GSE116256  149            149  T010003   Human            NaN   \n",
      "\n",
      "   Patients   Cells      Platform Pri...Meta  ...  MaxRSS MaxVMSize  ReqMem  \\\n",
      "0       2.0   3,994  10x Genomics    Primary  ...     NaN       NaN  24000M   \n",
      "1      11.0  37,936  10x Genomics    Primary  ...     NaN       NaN    125G   \n",
      "2       1.0   2,904  10x Genomics   Relapsed  ...     NaN       NaN  24000M   \n",
      "3       7.0  10,800  10x Genomics    Primary  ...     NaN       NaN  24000M   \n",
      "4      21.0  38,348    Smart-seq2    Primary  ...     NaN       NaN    125G   \n",
      "\n",
      "   TotalCPU  file.size  date.modification time.modification  \\\n",
      "0   10:14.9        41M              6-Aug             15:51   \n",
      "1   2:29:37       196M              6-Aug             15:51   \n",
      "2   11:07.6        34M              6-Aug             15:51   \n",
      "3   00:14.7        62M             16-Aug             15:29   \n",
      "4   2:41:39       152M              6-Aug             15:51   \n",
      "\n",
      "                   file.name   State_h5  in_df_name  \n",
      "0  AEL_GSE142213.pipeline.h5  COMPLETED        True  \n",
      "1  ALL_GSE132509.pipeline.h5  COMPLETED        True  \n",
      "2  ALL_GSE153697.pipeline.h5  COMPLETED        True  \n",
      "3  ALL_GSE154109.pipeline.h5  COMPLETED        True  \n",
      "4  AML_GSE116256.pipeline.h5  COMPLETED        True  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame loading, replace with your actual data loading method\n",
    "# Assume metadata and df are already loaded as per your setup\n",
    "\n",
    "# Create a set from df['name'] for efficient membership testing\n",
    "name_set = set(df['filename'])\n",
    "\n",
    "# Add the membership check column to metadata\n",
    "metadata['in_df_name'] = metadata['file.name'].isin(name_set)\n",
    "\n",
    "# Display the updated metadata DataFrame with all original columns plus the new 'in_df_name' column\n",
    "print(metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dataset.Name    X  dataset.index       ID Species      Treatment  \\\n",
      "0  AEL_GSE142213   25             25  T010001   Human            NaN   \n",
      "1  ALL_GSE132509  148            148  T010002   Human            NaN   \n",
      "2  ALL_GSE153697   13             13  T020082   Human  Immunotherapy   \n",
      "3  ALL_GSE154109   81             81  T020083   Human            NaN   \n",
      "4  AML_GSE116256  149            149  T010003   Human            NaN   \n",
      "\n",
      "   Patients   Cells      Platform Pri...Meta  ...  ReqMem TotalCPU file.size  \\\n",
      "0       2.0   3,994  10x Genomics    Primary  ...  24000M  10:14.9       41M   \n",
      "1      11.0  37,936  10x Genomics    Primary  ...    125G  2:29:37      196M   \n",
      "2       1.0   2,904  10x Genomics   Relapsed  ...  24000M  11:07.6       34M   \n",
      "3       7.0  10,800  10x Genomics    Primary  ...  24000M  00:14.7       62M   \n",
      "4      21.0  38,348    Smart-seq2    Primary  ...    125G  2:41:39      152M   \n",
      "\n",
      "   date.modification  time.modification                  file.name   State_h5  \\\n",
      "0              6-Aug              15:51  AEL_GSE142213.pipeline.h5  COMPLETED   \n",
      "1              6-Aug              15:51  ALL_GSE132509.pipeline.h5  COMPLETED   \n",
      "2              6-Aug              15:51  ALL_GSE153697.pipeline.h5  COMPLETED   \n",
      "3             16-Aug              15:29  ALL_GSE154109.pipeline.h5  COMPLETED   \n",
      "4              6-Aug              15:51  AML_GSE116256.pipeline.h5  COMPLETED   \n",
      "\n",
      "  in_df_name                    name  \\\n",
      "0       True  AEL_GSE142213.pipeline   \n",
      "1       True  ALL_GSE132509.pipeline   \n",
      "2       True  ALL_GSE153697.pipeline   \n",
      "3       True  ALL_GSE154109.pipeline   \n",
      "4       True  AML_GSE116256.pipeline   \n",
      "\n",
      "                                                path  \n",
      "0  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "1  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "2  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "3  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "4  /uufs/chpc.utah.edu/common/home/ychen-group1/I...  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.merge(metadata, df, how='left', left_on='file.name', right_on='filename')\n",
    "\n",
    "# Drop the additional 'name' column since it's redundant with 'Dataset.Name'\n",
    "result.drop('filename', axis=1, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"add_data_link.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iscvam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
